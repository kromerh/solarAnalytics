{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Time Series Forecasting\n",
    "\n",
    "Sources: \n",
    "- https://machinelearningmastery.com/how-to-get-started-with-deep-learning-for-time-series-forecasting-7-day-mini-course/\n",
    "- Machine Learning with Python Cookbook by Chris Albon\n",
    "- Talk by Ilja Rasin (https://www.linkedin.com/in/iljarasin/) at IBM Developer Unconference June 2019, Switzerland\n",
    "\n",
    "I found this course via LinkedIn posted by Steve Nouri (https://www.linkedin.com/in/stevenouri/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 01: Promise of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, you will discover the promise of deep learning methods for time series forecasting. <br>\n",
    "Generally, neural networks like Multilayer Perceptrons or MLPs provide capabilities that are offered by few algorithms, such as:<br>\n",
    " - Robust to Noise. Neural networks are robust to noise in input data and in the mapping function and can even support learning and prediction in the presence of missing values.\n",
    " - Nonlinear. Neural networks do not make strong assumptions about the mapping function and readily learn linear and nonlinear relationships.\n",
    " - Multivariate Inputs. An arbitrary number of input features can be specified, providing direct support for multivariate forecasting.\n",
    " - Multi-step Forecasts. An arbitrary number of output values can be specified, providing direct support for multi-step and even multivariate forecasting.\n",
    "\n",
    "#### From Machine Learning with Python Cookbook \n",
    "> Multilayer perceptrons are feedforward neural networks and represent the simplest artificial neural network used in any real-world setting. The name feedforward comes from the fact that the observations feature values are fed forward through the network. Each layer aims to transform the feature values so that the output at the end is the same as the target's value. \n",
    "\n",
    "> Forward propagagion means that an observation (usually a set of observations called a batch) is fed through the network and the output is compared with the true value of the observation using a loss function. \n",
    "\n",
    "> Backward propagation means that after the forward propagation the algorithm goes back through the network identifying how much each parameter has contributed to the error between predicted and true value. The optimization algorithm determines at each parameter how much each weight should be adjusted to improve the output.\n",
    "\n",
    "> The way neural networks learn is by repeating this process of forward and backpropagation for every observation multiple times. Each time all observations have been sent through the network is called an epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task\n",
    "\n",
    "For this lesson you must suggest one capability from both Convolutional Neural Networks and Recurrent Neural Networks that may be beneficial in modeling time series forecasting problems.\n",
    "\n",
    "Post your answer in the comments below. I would love to see what you discover.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "##### Convolutional Neural Networks (CNN):\n",
    "    Sources: \n",
    "        - https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/\n",
    "        \n",
    "CNNs have proven to be very effective in areas such as image recognition and classification. It takes an imput image, assigns importance, meaning that it learns weights \n",
    "and biases. The architecture of a CNN mimics the connectivity pattern of Neurons in the Human Brain. It is dense, meaning that \"everything is connected with everything\" and the resulting network is dense. Typically, a CNN consists of several layers with four main operations (typically there is a sequence of many CONV, RELU, CONV, RELU, POOL, CONV, RELU, VON, RELU, POOL, ...):\n",
    "    \n",
    "1. Convolution\n",
    "    Extract features from the input image using a feature detector (kernel). The resulting (filtered) image is called a Feature Map. In a CNN there are typically many different type of filters producing a Feature Map with a certain depth.\n",
    "2. ReLU (Rectified Linear Unit)\n",
    "    Introduces Non Linearity, by adding an additional element wise operation (on each pixel) after every Convolution operation. It replaces all negative pixel values in the Feature Map with zero.\n",
    "3. Pooling or Sub Sampling\n",
    "    Reduces the dimensionality of each Feature Map while retaining the most important information. Spatial pooling is usually Max, Average, Sum, ... For example in Max Pooling, a submatrix of the Feature Map is selected (i.e. 2x2) and take the largest element from the rectified feature map within this submatrix. Pooling progressively reduces spatial size of the input representation. It reduces dimensionality, also reduces number of parameters and computations in the network as a means to control overfitting. It also makes the network invariant to small transformations and help to arrive at an almost scale invariant representation of the image\n",
    "4. Classification\n",
    "    In the last step, a MLP is used in combination with i.e. a Softmax activation function to output probabilities, i.e. what is displayed in the image. \n",
    "        \n",
    "\n",
    "#### Recurrent Neural Networks (RNN) \n",
    "    Sources:\n",
    "        -https://machinelearningmastery.com/promise-recurrent-neural-networks-time-series-forecasting/\n",
    "RNNS (like LSTM) allow the explicit handling of order between observations when learning a mapping function from inputs to outputs. What this means is that there can be a layout of the network such that the connection between input layer and encoder layer 1 is dense, the connection within the network are recurrent, i.e. not dense, and the connection between decoder and output layer is again dense. That way the encoder layer learns to \"read\" the data and puts out a prediction, but the decoder layer does not consider the output of the encoder, it only considers the \"thought\" process that the encoder underwent and takes it from there.\n",
    "\n",
    "The promise of recurrent neural networks is that the temporal dependence in the input data can be learned. That a fixed set of lagged observations does not need to be specified. Rather than having a single multi-tasking cell, the model will use two specialised cells. One for memorising important events of the past (encoder) and one for converting the important events into a prediction of the future (decoder).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 02: How to Transform Data for Time Series\n",
    "\n",
    "In this lesson, you will discover how to transform your time series data into a supervised learning format.\n",
    "\n",
    "The majority of practical machine learning uses supervised learning.\n",
    "\n",
    "Supervised learning is where you have input variables (X) and an output variable (y) and you use an algorithm to learn the mapping function from the input to the output. The goal is to approximate the real underlying mapping so well that when you have new input data, you can predict the output variables for that data.\n",
    "\n",
    "Time series data can be phrased as supervised learning.\n",
    "\n",
    "Given a sequence of numbers for a time series dataset, we can restructure the data to look like a supervised learning problem. We can do this by using previous time steps as input variables and use the next time step as the output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task\n",
    "\n",
    "For this lesson you must develop Python code to transform the daily female births dataset into a supervised learning format with some number of inputs and one output.\n",
    "\n",
    "You can download the dataset from here: daily-total-female-births.csv\n",
    "\n",
    "Post your answer in the comments below. I would love to see what you discover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Births</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959-01-01</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959-01-02</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959-01-03</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959-01-04</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959-01-05</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Births\n",
       "0  1959-01-01      35\n",
       "1  1959-01-02      32\n",
       "2  1959-01-03      30\n",
       "3  1959-01-04      31\n",
       "4  1959-01-05      44"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/time_series_course_data/daily-total-female-births.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of df:\n",
      "     0    1    2    3\n",
      "0  1.0  2.0  3.0  4.0\n",
      "1  2.0  3.0  4.0  5.0\n",
      "2  3.0  4.0  5.0  6.0\n",
      "3  4.0  5.0  6.0  7.0\n",
      "4  5.0  6.0  7.0  8.0 \n",
      "\n",
      "Tail of df:\n",
      "       0     1     2     3\n",
      "91  92.0  93.0  94.0  95.0\n",
      "92  93.0  94.0  95.0  96.0\n",
      "93  94.0  95.0  96.0  97.0\n",
      "94  95.0  96.0  97.0  98.0\n",
      "95  96.0  97.0  98.0  99.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define the window width\n",
    "window_size = 3\n",
    "\n",
    "# make a test series to develop algorithm\n",
    "s = pd.Series(np.arange(1,100,1))\n",
    "\n",
    "# loop to make a new row in the dataframe \n",
    "df_window = pd.DataFrame()\n",
    "for ii in range(0,len(s)-window_size):\n",
    "    t = s.shift(-ii).values[0:window_size+1]\n",
    "    df_window = df_window.append(pd.Series(t),ignore_index=True)\n",
    "    \n",
    "#     print(t, np.isnan(t).any()) # I used this to check if one of the rows contain a nan\n",
    "print(\"Head of df:\")\n",
    "print(df_window.head(),\"\\n\")\n",
    "\n",
    "print(\"Tail of df:\")\n",
    "print(df_window.tail(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function\n",
    "\n",
    "def transformDataSetTimeSeries(s):\n",
    "    \"\"\"\n",
    "    Takes a series as an input and \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      35\n",
       "1      32\n",
       "2      30\n",
       "3      31\n",
       "4      44\n",
       "5      29\n",
       "6      45\n",
       "7      43\n",
       "8      38\n",
       "9      27\n",
       "10     38\n",
       "11     33\n",
       "12     55\n",
       "13     47\n",
       "14     45\n",
       "15     37\n",
       "16     50\n",
       "17     43\n",
       "18     41\n",
       "19     52\n",
       "20     34\n",
       "21     53\n",
       "22     39\n",
       "23     32\n",
       "24     37\n",
       "25     43\n",
       "26     39\n",
       "27     35\n",
       "28     44\n",
       "29     38\n",
       "       ..\n",
       "335    32\n",
       "336    46\n",
       "337    41\n",
       "338    34\n",
       "339    33\n",
       "340    36\n",
       "341    49\n",
       "342    43\n",
       "343    43\n",
       "344    34\n",
       "345    39\n",
       "346    35\n",
       "347    52\n",
       "348    47\n",
       "349    52\n",
       "350    39\n",
       "351    40\n",
       "352    42\n",
       "353    42\n",
       "354    53\n",
       "355    39\n",
       "356    40\n",
       "357    38\n",
       "358    44\n",
       "359    34\n",
       "360    37\n",
       "361    52\n",
       "362    48\n",
       "363    55\n",
       "364    50\n",
       "Name: Births, Length: 365, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Births']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
